{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgrM/pfdaiwzmp45vXUZV8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Tm4JsOME044R","executionInfo":{"status":"ok","timestamp":1695251779531,"user_tz":-600,"elapsed":1661,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report\n","from ast import literal_eval"]},{"cell_type":"markdown","source":["# Connect to Google Drive\n","\n","*   from google.colab import drive: This line of code imports a module called\n","\"drive\" from the \"google.colab\" library. The purpose of this module is to provide functionality for interacting with Google Drive, which is a cloud storage service provided by Google.\n","*   drive.mount('/content/drive'): This line of code calls the \"mount\" function from the \"drive\" module and passes '/content/drive' as an argument to it. The function's objective is to mount (connect) Google Drive to the current working environment within Google Colab. Once executed, this code establishes a connection between Google Drive and your Colab environment, making it possible to access and manipulate files and data stored in Google Drive directly from your Colab notebooks."],"metadata":{"id":"eET2_Q7WDXZ0"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"a1vEgfwD2ATG","executionInfo":{"status":"ok","timestamp":1695251975652,"user_tz":-600,"elapsed":18303,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"55438e0b-6094-4dba-9288-d97d4aa217bd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Split dataset"],"metadata":{"id":"EPfh2em9E380"}},{"cell_type":"markdown","source":["The provided code snippet is a common step in machine learning for splitting a dataset into two subsets: a training set and a test set. This split is essential for training and evaluating machine learning models. Here's what each part of the code does:\n","\n","**X_train and y_train:** These variables will hold the features (X) and labels (y) of the training set, respectively. The training set is used to train the machine learning model.\n","\n","**X_test and y_test:** These variables will hold the features (X) and labels (y) of the test set, respectively. The test set is used to evaluate the model's performance after it has been trained on the training data. It provides an independent dataset to assess how well the model generalizes to new, unseen data.\n","\n","**train_test_split**(X, y, test_size=0.2, random_state=42): This function is typically provided by machine learning libraries like scikit-learn (sklearn) and is used to split the dataset into training and test sets.\n","\n","*   **X:** This should be your feature matrix, containing the input data.\n","*   **y:** This should be your target or label vector, containing the corresponding labels for each data point.\n","\n","*   **test_size=0.2:** This parameter specifies the proportion of the dataset that should be allocated to the test set. In this case, it's set to 20%, meaning that 20% of the data will be used for testing, and the remaining 80% will be used for training.\n","*   **random_state=42:** This parameter is used to seed the random number generator for reproducibility. Setting it to a specific value (e.g., 42) ensures that you get the same split every time you run the code. It's helpful for debugging and ensuring consistent results.\n","\n","After executing this code, your dataset (X and y) will be divided into a training set (X_train, y_train) and a test set (X_test, y_test), following the specified split ratio. You can then use these sets to train and evaluate your machine learning models."],"metadata":{"id":"o0VjSAe_DuUC"}},{"cell_type":"code","source":["# Load CSV file into DataFrame\"\n","df = pd.read_csv('/content/drive/My Drive/30016/new_file_with_vectors.csv')\n","\n","# To convert the 'Feature_Vector' column from a string to a list and then into a NumPy array\n","df['Feature_Vector'] = df['Feature_Vector'].apply(literal_eval).apply(np.array)\n","\n","# To convert the 'Feature_Vector' column\n","X = np.stack(df['Feature_Vector'].values)\n","\n","# Use the 'Email Type' column as labels.\n","y = df['Email Type'].values\n","\n","#  split a dataset into a training set and a test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Now, you have your training and test sets\n","print(\"Training Set (X_train, y_train):\")\n","print(X_train)\n","print(y_train)\n","\n","print(\"\\nTest Set (X_test, y_test):\")\n","print(X_test)\n","print(y_test)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"GGu5cpXW1w90","executionInfo":{"status":"ok","timestamp":1695252009988,"user_tz":-600,"elapsed":29463,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"b8e31d80-ae26-4785-a651-c3b3a368351e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set (X_train, y_train):\n","[[-0.06365381  0.33708285  0.25972635 ... -0.18531946  0.28610983\n","  -0.32812821]\n"," [-0.59569101  0.43483159  0.2401536  ... -0.55423564  0.44989784\n","  -0.46823569]\n"," [ 0.01979951  0.56385286  0.18379596 ... -0.28178019  0.32619213\n","  -0.12823096]\n"," ...\n"," [-0.18408333  0.37067542  0.16043905 ...  0.22429176 -0.03252939\n","  -0.25497596]\n"," [-0.15068387  0.2502145   0.11821755 ... -0.44579493  0.12311342\n","  -0.1493098 ]\n"," [ 0.28490031  0.03255535  0.28461433 ...  0.28652487  0.59897806\n","  -0.8500713 ]]\n","['Safe Email' 'Safe Email' 'Safe Email' ... 'Safe Email' 'Phishing Email'\n"," 'Phishing Email']\n","\n","Test Set (X_test, y_test):\n","[[ 0.04000142  0.14879549  0.20035583 ... -0.11181284  0.27778296\n","  -0.1077499 ]\n"," [-0.36007181  0.3893119   0.40374841 ... -0.26885068  0.22512174\n","  -0.20499668]\n"," [-0.10345544  0.41563723  0.14372655 ... -0.33273552  0.21169822\n","  -0.38920602]\n"," ...\n"," [ 0.25351475  0.63477441  0.02968802 ... -0.13958492  0.19093559\n","  -0.38318701]\n"," [-0.12648102  0.24100764  0.19604423 ... -0.1895384   0.43431546\n","  -0.60450759]\n"," [-0.09202302  0.48239761  0.16664071 ... -0.42139754  0.09135581\n","  -0.29539788]]\n","['Phishing Email' 'Safe Email' 'Safe Email' ... 'Phishing Email'\n"," 'Safe Email' 'Safe Email']\n"]}]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"VsS2yj0L5Olf"}},{"cell_type":"markdown","source":["**clf = DecisionTreeClassifier()**: In this line, a decision tree classifier object (clf) is created. A decision tree classifier is a machine learning algorithm used for classification tasks. It builds a decision tree model based on the features and labels provided during training."],"metadata":{"id":"eeHIm3I25fWa"}},{"cell_type":"markdown","source":["**clf.fit(X_train, y_train):** Here, the decision tree classifier (clf) is trained or \"fit\" using the training data (X_train and y_train). X_train contains the feature vectors (input data) from the training dataset, and y_train contains the corresponding labels (the correct classifications).\n","\n","The classifier uses this training data to learn the patterns and relationships between features and labels, essentially constructing a decision tree that can make predictions based on the learned rules."],"metadata":{"id":"Pp_l76rE5ysH"}},{"cell_type":"code","source":["# Create a decision tree classifier and train it.\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"l1O6XUqD5Nvo","executionInfo":{"status":"ok","timestamp":1695252168715,"user_tz":-600,"elapsed":12516,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"86a01b66-477a-441d-9fd7-d9833e4ba139"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Predict the result"],"metadata":{"id":"2xNKzOs65joM"}},{"cell_type":"markdown","source":["**y_pred = clf.predict(X_test)**: After the classifier is trained, it is used to make predictions on a separate dataset, the test set (X_test). The predict method is called on the trained classifier (clf), passing in the test data (X_test). This line of code generates predicted labels (y_pred) for the test data based on the learned decision tree model.\n","\n","The predicted labels (y_pred) represent the classifier's best guess at the class (category) of each item in the test set, based on what it learned during training."],"metadata":{"id":"cr0SVMoD51j1"}},{"cell_type":"code","source":["# Make predictions on the test set.\n","y_pred = clf.predict(X_test)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy6KDxgt5kfB","executionInfo":{"status":"ok","timestamp":1695169801778,"user_tz":-600,"elapsed":361,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"0b23f601-d319-4b74-c396-90b4d2e68b41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Phishing Email' 'Safe Email' 'Phishing Email' ... 'Phishing Email'\n"," 'Safe Email' 'Safe Email']\n"]}]},{"cell_type":"markdown","source":["# **Evaluation**\n","\n","\"classification_report\" is not a standalone function. It is a feature typically provided in machine learning libraries like Scikit-Learn to generate performance reports for classification models. In Scikit-Learn, you can use \"sklearn.metrics.classification_report\" to generate a classification report. This function takes two parameters:\n","\n","**\"y_true\": An array or list containing the true class labels, typically the actual labels from the test set.**\n","\n","**\"y_pred\": An array or list containing the predicted class labels, typically the model's predictions on the test set.**"],"metadata":{"id":"Ls3Eepoi3rAt"}},{"cell_type":"markdown","source":["**Explain**\n","\n","**Precision**: Precision is the proportion of samples predicted as positive (Phishing Email or Safe Email) that are actually positive. For the Phishing Email and Safe Email categories, the precision values are 0.89 and 0.95, respectively. This means that when the model predicts an email as Phishing Email or Safe Email, it is correct 89% and 95% of the time for these categories, respectively.\n","\n","**Recall**: Recall is the proportion of actual positive samples that were correctly predicted as positive by the model. For the Phishing Email and Safe Email categories, the recall values are 0.92 and 0.93, respectively. This indicates that the model correctly identifies 92% and 93% of the actual Phishing Emails and Safe Emails.\n","\n","**F1-Score**: The F1-Score is the harmonic mean of precision and recall and is used to balance these two metrics. For the Phishing Email and Safe Email categories, the F1-Scores are 0.91 and 0.94, respectively. Higher F1-Scores suggest a good balance between precision and recall.\n","\n","**Support**: Support represents the number of samples for each category in the test dataset. In this report, there are 1428 samples for Phishing Email and 2298 samples for Safe Email.\n","\n","**Accuracy**: Accuracy indicates the proportion of correctly classified samples in the entire test dataset. The accuracy is 0.93, meaning that 93% of the test samples are classified correctly.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"rVwgwHl14gLl"}},{"cell_type":"code","source":["# print the result\n","# Assuming you have the true labels (y_true) and predicted labels (y_pred)\n","# from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKtPmD8X3qAX","executionInfo":{"status":"ok","timestamp":1695167865441,"user_tz":-600,"elapsed":401,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"bebceaa3-b558-4570-c872-8afe65b16acf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                precision    recall  f1-score   support\n","\n","Phishing Email       0.89      0.92      0.91      1428\n","    Safe Email       0.95      0.93      0.94      2298\n","\n","      accuracy                           0.93      3726\n","     macro avg       0.92      0.93      0.92      3726\n","  weighted avg       0.93      0.93      0.93      3726\n","\n"]}]},{"cell_type":"markdown","source":["**Example1: classification_report**\n","\n","y_true = [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]  # True labels\n","\n","y_pred = [0, 1, 0, 0, 1, 1, 1, 1, 0, 0]  # Model predictions"],"metadata":{"id":"r78eTCpEFlle"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Assuming you already have the model's predictions y_pred and the true labels y_true\n","y_true = [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]  # True labels\n","y_pred = [0, 1, 0, 0, 1, 1, 1, 1, 0, 0]  # Model predictions\n","\n","# Use the classification_report function to generate the report\n","report = classification_report(y_true, y_pred)\n","\n","# Print the report\n","print(report)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPIs_ek2FO7M","executionInfo":{"status":"ok","timestamp":1695255166588,"user_tz":-600,"elapsed":329,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"1d7cec0f-528a-48f2-e8b5-111f809aaeec"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.75      0.67         4\n","           1       0.80      0.67      0.73         6\n","\n","    accuracy                           0.70        10\n","   macro avg       0.70      0.71      0.70        10\n","weighted avg       0.72      0.70      0.70        10\n","\n"]}]},{"cell_type":"markdown","source":["Let's break down the various sections of this report:\n","\n","**precision**: Precision refers to the proportion of samples predicted as a specific class that truly belong to that class. For class 0, precision is 0.60, and for class 1, precision is 0.80. This indicates that the model's accuracy of predictions for class 0 is 60%, and for class 1, it's 80%.\n","\n","**recall**: Recall is the proportion of actual samples of a specific class that were correctly predicted as that class. For class 0, recall is 0.75, and for class 1, recall is 0.67. This means that the model correctly captured 75% of class 0 samples and 67% of class 1 samples.\n","\n","**f1-score**: The F1 score is the harmonic mean of precision and recall and is used to balance accuracy and coverage. A higher F1 score indicates a better balance between precision and recall. For class 0, the F1 score is 0.67, and for class 1, it's 0.73.\n","\n","**support**: Support indicates the number of samples belonging to each class in the true dataset. Class 0 has 4 samples, and class 1 has 6 samples.\n","\n","**accuracy**: Accuracy represents the overall proportion of correctly predicted samples. In this case, the overall accuracy is 0.70, indicating that the model correctly predicted 70% of the samples.\n","\n","**macro avg**: Macro average calculates the average of all class-specific metrics (precision, recall, F1-score). It is a performance measure that doesn't take class imbalances into account. In this case, the macro-averaged F1 score is 0.70.\n","\n","**weighted avg**: Weighted average computes the average of all class-specific metrics while considering class imbalances. It is a performance measure that gives more weight to classes with more samples. In this case, the weighted-averaged F1 score is 0.70"],"metadata":{"id":"ZuwDqcSRFyyj"}},{"cell_type":"markdown","source":["**Example2: accuracy_score**\n","\n","y_true = [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]  # True labels\n","\n","y_pred = [0, 1, 0, 0, 1, 1, 1, 1, 0, 0]  # Model predictions"],"metadata":{"id":"ovomMdj9FzAW"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","# Assuming you already have the model's predictions y_pred and the true labels y_true\n","y_true = [0, 1, 1, 0, 1, 0, 1, 1, 1, 0]  # True labels\n","y_pred = [0, 1, 0, 0, 1, 1, 1, 1, 0, 0]  # Model predictions\n","\n","# Calculate accuracy using the accuracy_score function\n","accuracy = accuracy_score(y_true, y_pred)\n","\n","# Print the accuracy\n","print(f\"Accuracy: {accuracy}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBj9EkhvGE1P","executionInfo":{"status":"ok","timestamp":1695255407539,"user_tz":-600,"elapsed":427,"user":{"displayName":"yicun tian","userId":"05767386441647099177"}},"outputId":"3f94affd-1df0-49ef-9727-388c20792fe9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7\n"]}]},{"cell_type":"markdown","source":["In this example, the accuracy_score function takes two arguments: the true labels y_true and the model's predicted labels y_pred. It calculates the accuracy of the model and returns a score that represents the proportion of correctly predicted samples."],"metadata":{"id":"SMVTsNw9GSgS"}}]}